{
    "command-line": "3dTfitter [RHS] [LHS] [POLORT] [VTHR] [FALTUNG] [LSQFIT] [L1FIT] [L2LASSO] [L2SQRTLASSO] [CONSIGN] [CONSFAL] [PREFIX] [LABEL] [FITTS] [ERRSUM] [MASK] [QUIET]",
    "description": "tool description",
    "inputs": [
        {
            "command-line-flag": "-RHS",
            "description": "Specifies the right-hand-side 3D+time dataset. ('rset' can also be a 1D file with 1 column) * Exactly one '-RHS' option must be given to 3dTfitter.",
            "id": "RHS",
            "name": "RHS",
            "optional": true,
            "type": "String",
            "value-key": "[RHS]"
        },
        {
            "command-line-flag": "-LHS",
            "description": "Specifies a column (or columns) of the left-hand-side matrix. * More than one 'lset' can follow the '-LHS' option, but each input filename must NOT start with the '-' character! * Or you can use multiple '-LHS' options, if you prefer. * Each 'lset' can be a 3D+time dataset, or a 1D file with 1 or more columns. * A 3D+time dataset defines one column in the LHS matrix. ++ If 'rset' is a 1D file, then you cannot input a 3D+time dataset with '-LHS'. ++ If 'rset' is a 3D+time dataset, then the 3D+time dataset(s) input with '-LHS' must have the same voxel grid as 'rset'. * A 1D file defines as many columns in the LHS matrix as are in the file. ++ For example, you could input the LHS matrix from the .xmat.1D file output by 3dDeconvolve, if you wanted to repeat the same linear regression using 3dTfitter, for some bizarre unfathomable twisted psychotic reason. ** If you have a problem where some LHS vectors might be tiny, causing stability problems, you can choose to omit them by using the '-vthr' option.  By default, only all-zero vectors will be omitted from the regression. ** Note that if the scales of the LHS vectors are grossly different (e.g., 0 < vector#1 < 0.01  and  0 < vector#2 < 1000), then numerical errors in the calculations might cause the results to be unreliable.  To avoid this problem, you can scale the vectors (before running 3dTfitter) so that they have similar magnitudes. ** Note that if you are fitting a time series dataset that has nonzero mean, then at least some of your basis vectors should have nonzero mean, or you won't be able to get a good fit.  If necessary, use '-polort 0' to fit the mean value of the dataset, so that the zero-mean LHS vectors can do their work in fitting the fluctuations in the data! [This means you, HJJ!] *** Columns are assembled in the order given on the command line, which means that LHS parameters will be output in that order! *** If all LHS inputs are 1D vectors AND you are using least squares fitting without constraints, then 3dDeconvolve would be more efficient, since each voxel would have the same set of equations -- a fact that 3dDeconvolve exploits for speed. ++ But who cares about CPU time?  Come on baby, light my fire!",
            "id": "LHS",
            "name": "LHS",
            "optional": true,
            "type": "String",
            "value-key": "[LHS]"
        },
        {
            "command-line-flag": "-polort",
            "description": "Add 'p+1' Legendre polynomial columns to the LHS matrix. * These columns are added to the LHS matrix AFTER all other columns specified by the '-LHS' option, even if the '-polort' option appears before '-LHS' on the command line. ** By default, NO polynomial columns will be used.",
            "id": "POLORT",
            "name": "POLORT",
            "optional": true,
            "type": "String",
            "value-key": "[POLORT]"
        },
        {
            "command-line-flag": "-vthr",
            "description": "The value 'v' (between 0.0 and 0.09, inclusive) defines the threshold below which LHS vectors will be omitted from the regression analysis.  Each vector's L1 norm (sum of absolute values) is computed.  Any vector whose L1 norm is less than or equal to 'v' times the largest L1 norm will not be used in the analysis, and will get 0 weight in the output.  The purpose of this option is to let you have tiny inputs and have them be ignored. * By default, 'v' is zero ==> only exactly zero LHS columns will be ignored. ** Prior to 18 May 2010, the built-in (and fixed) value of 'v' was 0.000333.  Thus, to get the old results, you should use option '-vthr 0.000333' -- this means YOU, Rasmus Birn!  -------------- DECONVOLUTION: --------------",
            "id": "VTHR",
            "name": "VTHR",
            "optional": true,
            "type": "String",
            "value-key": "[VTHR]"
        },
        {
            "command-line-flag": "-FALTUNG",
            "description": "-FALTUNG fset fpre pen fac = Specifies a convolution (German: Faltung) model to be added to the LHS matrix.  Four arguments follow the option:  -->** 'fset' is a 3D+time dataset or a 1D file that specifies the known kernel of the convolution. * fset's time point [0] is the 0-lag point in the kernel, [1] is the 1-lag into the past point, etc. ++ Call the data Z(t), the unknown signal S(t), and the known kernel H(t).  The equations being solved for the set of all S(t) values are of the form Z(t) = H(0)S(t) + H(1)S(t-1) + ... + H(L)S(t-L) + noise where L is the last index in the kernel function. ++++ N.B.: The TR of 'fset' (the source of H) and the TR of the RHS dataset (the source of Z) MUST be the same, or the deconvolution results will be revoltingly meaningless drivel (or worse)!  -->** 'fpre' is the prefix for the output time series S(t) to be created -- it will have the same length as the input 'rset' time series. ++ If you don't want this time series (why?), set 'fpre' to be the string 'NULL'. ++ If you want to see the fit of the model to the data (a very good idea), use the '-fitts' option, which is described later.  -->** 'pen' selects the type of penalty function to be applied to constrain the deconvolved time series: ++ The following penalty functions are available: P0[s] = f^q * sum{ |S(t)|^q } P1[s] = f^q * sum{ |S(t)-S(t-1)|^q } P2[s] = f^q * sum{ |2*S(t)-S(t-1)-S(t+1)|^q } P3[s] = f^q * sum{ |3*S(t)-3*S(t-1)-S(t+1)+S(t-2)|^q } where S(t) is the deconvolved time series; where q=1 for L1 fitting, q=2 for L2 fitting; where f is the value of 'fac' (defined below). P0 tries to keep S(t) itself small P1 tries to keep point-to-point fluctuations in S(t) small (1st derivative) P2 tries to keep 3 point fluctuations in S(t) small (2nd derivative) P3 tries to keep 4 point fluctuations in S(t) small (3nd derivative) ++ Higher digits try to make the result function S(t) smoother.  If a smooth result makes sense, then use the string '012' or '0123' for 'pen'. ++ In L2 regression, these penalties are analogous to Wiener (frequency space) deconvolution, with noise spectra proportional to P0 ==> fac^2 * 1 (constant in frequency) P1 ==> fac^2 * freq^2 P2 ==> fac^2 * freq^4 P3 ==> fac^2 * freq^6 However, 3dTfitter does deconvolution in the time domain, not the frequency domain, and you can choose to use L2, L1, or LASSO (L2+L1) regression. ++ The value of 'pen' is a combination of the digits '0', '1', '2', and/or '3'; for example: 0 = use P0 only 1 = use P1 only 2 = use P2 only 3 = use P3 only 01 = use P0+P1 (the sum of these two functions) 02 = use P0+P2 12 = use P1+P2 012 = use P0+P1+P2 (sum of three penalty functions) 0123 = use P0+P1+P2+P3 (et cetera) If 'pen' does not contain any of the digits 0..3, then '01' will be used.  -->** 'fac' is the positive weight 'f' for the penalty function: ++ if fac < 0, then the program chooses a penalty factor for each voxel separately and then scales that by -fac. ++ use fac = -1 to get this voxel-dependent factor unscaled. (this is a very reasonable place to start, by the way :-) ++ fac = 0 is a special case: the program chooses a range of penalty factors, does the deconvolution regression for each one, and then chooses the fit it likes best (as a tradeoff between fit error and solution size). ++ fac = 0 will be MUCH slower since it solves about 20 problems for each voxel and then chooses what it likes. setenv AFNI_TFITTER_VERBOSE YES to get some progress reports, if you want to see what it is doing. ++ Instead of using fac = 0, a useful alternative is to do some test runs with several negative values of fac, [e.g., -1, -2, and -3] and then look at the results to determine which one is most suitable for your purposes. ++ It is a good idea to experiment with different fac values, so you can see how the solution varies, and so you can get some idea of what penalty level to use for YOUR problems. ++ SOME penalty has to be applied, since otherwise the set of linear equations for S(t) is under-determined and/or ill-conditioned!  ** If '-LHS' is used with '-FALTUNG', those basis vectors can be thought of as a baseline to be regressed out at the same time the convolution model is fitted. ++ When '-LHS' supplies a baseline, it is important that penalty type 'pen' include '0', so that the collinearity between convolution with a constant S(t) and a constant baseline can be resolved! ++ Instead of using a baseline here, you could project the baseline out of a dataset or 1D file using 3dDetrend, before using 3dTfitter.  *** At most one '-FALTUNG' option can be used!!!  *** Consider the time series model Z(t) = K(t)*S(t) + baseline + noise, where Z(t) = data time series (in each voxel) K(t) = kernel (e.g., hemodynamic response function) S(t) = stimulus time series baseline = constant, drift, etc. and * = convolution in time Then program 3dDeconvolve solves for K(t) given S(t), whereas 3dTfitter -FALTUNG solves for S(t) given K(t).  The difference between the two cases is that K(t) is presumed to be causal and have limited support, while S(t) is a full-length time series.  *** Presumably you know this already, but deconvolution in the Fourier domain          -1 S(t) = F  { F[Z] / F[K] } (where F[] is the Fourier transform) is a bad idea, since division by small values F[K] will grotesquely amplify the noise.  3dTfitter does NOT even try to do such a silly thing.  ****** Deconvolution is a tricky business, so be careful out there! ++ e.g., Experiment with the different parameters to make sure the results in your type of problems make sense. -->>++ Look at the results and the fits with AFNI (or 1dplot)! Do not blindly assume that the results are accurate. ++ There is no guarantee that the automatic selection of of the penalty factor will give usable results for your problem! ++ You should probably use a mask dataset with -FALTUNG, since deconvolution can often fail on pure noise time series. ++ Unconstrained (no '-cons' options) least squares ('-lsqfit') is normally the fastest solution method for deconvolution. This, however, may only matter if you have a very long input time series dataset (e.g., more than 1000 time points). ++ For unconstrained least squares deconvolution, a special sparse matrix algorithm is used for speed.  If you wish to disable this for some reason, set environment variable AFNI_FITTER_RCMAT to NO before running the program. ++ Nevertheless, a FALTUNG problem with more than 1000 time points will probably take a LONG time to run, especially if 'fac' is chosen to be 0.  ---------------- SOLUTION METHOD: ----------------",
            "id": "FALTUNG",
            "name": "FALTUNG",
            "optional": true,
            "type": "String",
            "value-key": "[FALTUNG]"
        },
        {
            "command-line-flag": "-lsqfit",
            "description": "Solve equations via least squares [the default method]. * This is sometimes called L2 regression by mathematicians. * '-l2fit' and '-L2' are synonyms for this option.",
            "id": "LSQFIT",
            "name": "LSQFIT",
            "optional": true,
            "type": "String",
            "value-key": "[LSQFIT]"
        },
        {
            "command-line-flag": "-l1fit",
            "description": "Solve equations via least sum of absolute residuals. * This is sometimes called L1 regression by mathematicians. * '-L1' is a synonym for this option. * L1 fitting is usually slower than L2 fitting, but is perhaps less sensitive to outliers in the data. ++ L1 deconvolution might give nicer looking results when you expect the deconvolved signal S(t) to have large-ish sections where S(t) = 0. [The LASSO solution methods can also have this property.] * L2 fitting is statistically more efficient when the noise is KNOWN to be normally (Gaussian) distributed (and a bunch of other assumptions are also made). ++ Where such KNOWLEDGE comes from is an interesting question.",
            "id": "L1FIT",
            "name": "L1FIT",
            "optional": true,
            "type": "String",
            "value-key": "[L1FIT]"
        },
        {
            "command-line-flag": "-l2lasso",
            "description": "-l2lasso lam [i j k ...] = Solve equations via least squares with a LASSO (L1) penalty on the coefficients. * The positive value 'lam' after the option name is the weight given to the penalty. ++ As a rule of thumb, you can try lam = 2 * sigma, where sigma = standard deviation of noise, but that requires you to have some idea what the noise level is. ++ If you enter 'lam' as a negative number, then the code will CRUDELY estimate sigma and then scale abs(lam) by that value -- in which case, you can try lam = -2 (or so) and see if that works well for you. ++ Or you can use the Square Root LASSO option (next), which (in theory) does not need to know sigma when setting lam. * Optionally, you can supply a list of parameter indexes (after 'lam') that should NOT be penalized in the the fitting process (e.g., traditionally, the mean value is not included in the L1 penalty.)  Indexes start at 1, as in 'consign' (below). ++ In deconvolution ('-FALTUNG'), all baseline parameters (from '-LHS' and/or '-polort') are automatically non-penalized, so there is no point to using this un-penalizing feature. ++ If you are NOT doing deconvolution, then you'll need this option to un-penalize the '-polort' parameters (if desired). ** LASSO-ing herein should be considered experimental, and its implementation is subject to change!  You should definitely play with different 'lam' values to see how well they work for your particular types of problems.  Algorithm is here: ++ TT Wu and K Lange. Coordinate descent algorithms for LASSO penalized regression. Annals of Applied Statistics, 2: 224-244 (2008). http://arxiv.org/abs/0803.3876 * '-LASSO' is a synonym for this option.",
            "id": "L2LASSO",
            "name": "L2LASSO",
            "optional": true,
            "type": "String",
            "value-key": "[L2LASSO]"
        },
        {
            "command-line-flag": "-l2sqrtlasso",
            "description": "-l2sqrtlasso lam [i j k ...] = Similar to above option, but uses 'Square Root LASSO' instead: * Approximately speaking, LASSO minimizes E = Q2+lam*L1, where Q2=sum of squares of residuals and L1=sum of absolute values of all fit parameters, while Square Root LASSO minimizes sqrt(Q2)+lam*L1; the method and motivation is described here: ++ A Belloni, V Chernozhukov, and L Wang. Square-root LASSO: Pivotal recovery of sparse signals via conic programming (2010).  http://arxiv.org/abs/1009.5689 ++ A coordinate descent algorithm is also used for this optimization. ** A reasonable range of 'lam' to use is from 1 to 10 (or so); I suggest you start with 2 and see how well that works. ++ Unlike the pure LASSO option above, you do not need to give give a negative value for lam here -- there is no need for scaling by sigma. * The theoretical advantange of Square Root LASSO over standard LASSO is that a good choice of 'lam' doesn't depend on knowing the noise level in the data (that is what 'Pivotal' means in the paper's title). * '-SQRTLASSO' is a synonym for this option.  --------->>**** GENERAL NOTES ABOUT LASSO and SQUARE ROOT LASSO ****<<-------- * LASSO methods are the only way to solve a under-determined system with 3dTfitter -- one with more vectors on the RHS than time points.  However, a 'solution' to such a problem doesn't necessarily mean anything -- be careful out there! * LASSO methods will tend to push small coefficients down to zero.  This feature can be useful when doing deconvolution, if you expect the result to be zero over large-ish intervals. ++ L1 regression ('-l1fit') has a similar property, of course. ++ This difficult-to-estimate bias in the LASSO-computed coefficients makes it nearly impossible to provide reliable estimates of statistical significance for the fit (e.g., R^2, F, ...). * The actual penalty factor lambda used for a given coefficient is lam scaled by the L2 norm of the corresponding regression column. The purpose of this is to keep the penalties scale-free: if a regression column were doubled, then the corresponding fit coefficient would be cut in half; thus, to keep the same penalty level, lambda should also be doubled. * For '-l2lasso', a negative lam additionally means to scale by the estimate of sigma, as described earlier.  This feature does not apply to Square Root LASSO, however (if you give a negative lam to '-l2sqrtlasso', its absolute value is used). -->>** There is no 'best' value of lam; if you are lucky, there is is a range of lam values that give reasonable results. A good procedure to follow would be to use several different values of lam and see how the results vary; for example, the list lam = -1, -2, -4, -7, -10 might be a good starting point. * If you don't give ANY numeric value after the LASSO option (i.e., the next argument on the command line is another option), then the program will use '-3.1415926536' for the value of lam. * A tiny value of lam (say 0.01) should give almost the same results as pure L2 regression. * Data with a smaller signal-to-noise ratio will probably need larger values of lam -- you'll have to experiment. * The number of iterations used for the LASSO solution will be printed out for the first voxel solved, and for ever 10,000th one following -- this is mostly for my personal edification. -->>** Recall: \"3dTfitter is not for the casual user!\" This statement especially applies when using LASSO, which is a powerful tool -- and as such, can be dangerous if not used wisely.  --------------------- SOLUTION CONSTRAINTS: ---------------------",
            "id": "L2SQRTLASSO",
            "name": "L2SQRTLASSO",
            "optional": true,
            "type": "String",
            "value-key": "[L2SQRTLASSO]"
        },
        {
            "command-line-flag": "-consign",
            "description": "Follow this option with a list of LHS parameter indexes to indicate that the sign of some output LHS parameters should be constrained in the solution; for example: -consign +1 -3 which indicates that LHS parameter #1 (from the first -LHS) must be non-negative, and that parameter #3 must be non-positive.  Parameter #2 is unconstrained (e.g., the output can be positive or negative). * Parameter counting starts with 1, and corresponds to the order in which the LHS columns are specified. * Unlike '-LHS or '-label', only one '-consign' option can be used. * Do NOT give the same index more than once after '-consign' -- you can't specify that an coefficient is both non-negative and non-positive, for example! *** Constraints can be used with any of the 4 fitting methods. *** '-consign' constraints only apply to the '-LHS' fit parameters.  To constrain the '-FALTUNG' output, use the option below. * If '-consign' is not used, the signs of the fitted LHS parameters are not constrained.",
            "id": "CONSIGN",
            "name": "CONSIGN",
            "optional": true,
            "type": "String",
            "value-key": "[CONSIGN]"
        },
        {
            "command-line-flag": "-consFAL",
            "description": "Constrain the deconvolution time series from '-FALTUNG' to be positive if 'c' is '+' or to be negative if 'c' is '-'. * There is no way at present to constrain the deconvolved time series S(t) to be positive in some regions and negative in others. * If '-consFAL' is not used, the sign of the deconvolved time series is not constrained.  --------------- OUTPUT OPTIONS: ---------------",
            "id": "CONSFAL",
            "name": "CONSFAL",
            "optional": true,
            "type": "String",
            "value-key": "[CONSFAL]"
        },
        {
            "command-line-flag": "-prefix",
            "description": "Prefix for the output dataset (LHS parameters) filename. * Output datasets from 3dTfitter are always in float format. * If you don't give this option, 'Tfitter' is the prefix. * If you don't want this dataset, use 'NULL' as the prefix. * If you are doing deconvolution and do not also give any '-LHS' options, then this file will not be output, since it comprises the fit parameters for the '-LHS' vectors. -->>** If the input '-RHS' file is a .1D file, normally the output files are written in the AFNI .3D ASCII format, where each row contains the time series data for one voxel.  If you want to have these files written in the .1D format, with time represented down the column direction, be sure to put '.1D' on the end of the prefix, as in '-prefix Elvis.1D'.  If you use '-' or 'stdout' as the prefix, the resulting 1D file will be written to the terminal.  (See the fun fun fun examples, below.)",
            "id": "PREFIX",
            "name": "PREFIX",
            "optional": true,
            "type": "String",
            "value-key": "[PREFIX]"
        },
        {
            "command-line-flag": "-label",
            "description": "Specifies sub-brick labels in the output LHS parameter dataset. * More than one 'lb' can follow the '-label' option; however, each label must NOT start with the '-' character! * Labels are applied in the order given. * Normally, you would provide exactly as many labels as LHS columns.  If not, the program invents some labels.",
            "id": "LABEL",
            "name": "LABEL",
            "optional": true,
            "type": "String",
            "value-key": "[LABEL]"
        },
        {
            "command-line-flag": "-fitts",
            "description": "Prefix filename for the output fitted time series dataset. * Which is always in float format. * Which will not be written if this option isn't given! *** If you want the residuals, subtract this time series from the '-RHS' input using 3dcalc (or 1deval).",
            "id": "FITTS",
            "name": "FITTS",
            "optional": true,
            "type": "String",
            "value-key": "[FITTS]"
        },
        {
            "command-line-flag": "-errsum",
            "description": "Prefix filename for the error sums dataset, which is calculated from the difference between the input time series and the fitted time series (in each voxel): * Sub-brick #0 is the sum of squares of differences (L2 sum) * Sub-brick #1 is the sum of absolute differences (L1 sum) * The L2 sum value, in particular, can be used to produce a statistic to measure the significance of a fit model; cf. the 'Correlation Coefficient Example' far below.  -------------- OTHER OPTIONS: --------------",
            "id": "ERRSUM",
            "name": "ERRSUM",
            "optional": true,
            "type": "String",
            "value-key": "[ERRSUM]"
        },
        {
            "command-line-flag": "-mask",
            "description": "Read in dataset 'ms' as a mask; only voxels with nonzero values in the mask will be processed.  Voxels falling outside the mask will be set to all zeros in the output. * Voxels whose time series are all zeros will not be processed, even if they are inside the mask!",
            "id": "MASK",
            "name": "MASK",
            "optional": true,
            "type": "String",
            "value-key": "[MASK]"
        },
        {
            "command-line-flag": "-quiet",
            "description": "Don't print the fun fun fun progress report messages. * Why would you want to hide these delightful missives?  ---------------------- ENVIRONMENT VARIABLES: ---------------------- AFNI_TFITTER_VERBOSE  =  YES means to print out information during the fitting calculations. ++ Automatically turned on for 1 voxel -RHS inputs. AFNI_TFITTER_P1SCALE  =  number > 0 will scale the P1 penalty by this value (e.g., to count it more) AFNI_TFITTER_P2SCALE  =  number > 0 will scale the P2 penalty by this value AFNI_TFITTER_P3SCALE  =  number > 0 will scale the P3 penalty by this value You could set these values on the command line using the AFNI standard '-Dvariablename=value' command line option.  ------------ NON-Options: ------------ * There is no option to produce statistical estimates of the significance of the parameter estimates. ++ 3dTcorrelate might be useful, to compute the correlation between the '-fitts' time series and the '-RHS' input data. ++ You can use the '-errsum' option to get around this limitation, with enough cleverness. * There are no options for censoring or baseline generation (except '-polort'). ++ You could generate some baseline 1D files using 1deval, perhaps. * There is no option to constrain the range of the output parameters, except the semi-infinite ranges provided by '-consign' and/or '-consFAL'. * This program is NOT parallelized via OpenMP :-(  ------------------ Contrived Example: ------------------ The dataset 'atm' and 'btm' are assumed to have 99 time points each. We use 3dcalc to create a synthetic combination of these plus a constant plus Gaussian noise, then use 3dTfitter to fit the weights of these 3 functions to each voxel, using 4 different methods.  Note the use of the input 1D time series '1D: 99@1' to provide the constant term.  3dcalc -a atm+orig -b btm+orig -expr '-2*a+b+gran(100,20)' -prefix 21 -float 3dTfitter -RHS 21+orig -LHS atm+orig btm+orig '1D: 99@1' -prefix F2u -l2fit 3dTfitter -RHS 21+orig -LHS atm+orig btm+orig '1D: 99@1' -prefix F1u -l1fit 3dTfitter -RHS 21+orig -LHS atm+orig btm+orig '1D: 99@1' -prefix F1c -l1fit \\ -consign -1 +3 3dTfitter -RHS 21+orig -LHS atm+orig btm+orig '1D: 99@1' -prefix F2c -l2fit \\ -consign -1 +3  In the absence of noise and error, the output datasets should be #0 sub-brick = -2.0 in all voxels #1 sub-brick = +1.0 in all voxels #2 sub-brick = +100.0 in all voxels  ---------------------- Yet More Contrivances: ---------------------- You can input a 1D file for the RHS dataset, as in the example below, to fit a single time series to a weighted sum of other time series:  1deval -num 30 -expr 'cos(t)' > Fcos.1D 1deval -num 30 -expr 'sin(t)' > Fsin.1D 1deval -num 30 -expr 'cos(t)*exp(-t/20)' > Fexp.1D 3dTfitter -quiet -RHS Fexp.1D -LHS Fcos.1D Fsin.1D -prefix -  * Note the use of the '-' as a prefix to write the results (just 2 numbers) to stdout, and the use of '-quiet' to hide the divertingly funny and informative progress messages. * For the Jedi AFNI Masters out there, the above example can be carried out on using single complicated command line:  3dTfitter -quiet -RHS `1deval -1D: -num 30 -expr 'cos(t)*exp(-t/20)'` \\ -LHS `1deval -1D: -num 30 -expr 'cos(t)'`            \\ `1deval -1D: -num 30 -expr 'sin(t)'`            \\ -prefix -  resulting in the single output line below:  0.535479 0.000236338  which are respectively the fit coefficients of 'cos(t)' and 'sin(t)'.  -------------------------------- Contrived Deconvolution Example: -------------------------------- (1) Create a 101 point 1D file that is a block of 'activation' between points 40..50, convolved with a triangle wave kernel (the '-iresp' input below): 3dConvolve -input1D -polort -1 -num_stimts 1     \\ -stim_file 1 '1D: 40@0 10@1 950@0'    \\ -stim_minlag 1 0 -stim_maxlag 1 5     \\ -iresp 1 '1D: 0 1 2 3 2 1' -nlast 100 \\ | grep -v Result | grep -v '^$' > F101.1D  (2) Create a 3D+time dataset with this time series in each voxel, plus noise that increases with voxel 'i' index: 3dUndump -prefix Fjunk -dimen 100 100 1 3dcalc -a Fjunk+orig -b F101.1D     \\ -expr 'b+gran(0,0.04*(i+1))' \\ -float -prefix F101d /bin/rm -f Fjunk+orig.*  (3) Deconvolve, then look what you get by running AFNI: 3dTfitter -RHS F101d+orig -l1fit \\",
            "id": "QUIET",
            "name": "QUIET",
            "optional": true,
            "type": "String",
            "value-key": "[QUIET]"
        }
    ],
    "name": "tool name",
    "schema-version": "0.5",
    "suggested-resources": {
        "cpu-cores": 1,
        "ram": 1,
        "walltime-estimate": 60
    },
    "tags": {},
    "tool-version": "v0.1.0"
}